"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[3856],{8034:(e,l,a)=>{a.r(l),a.d(l,{assets:()=>i,contentTitle:()=>t,default:()=>m,frontMatter:()=>r,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"commands/LLM Locally","title":"LLM Locally","description":"To put an LLM locally (which works similar to ChatGPT) we need two components - Ollama and Open WebUI. In this process we need to use both Ollama and Open WebUI, that is why I made a separate file for detailing the process of making LLM work locally.","source":"@site/docs/commands/LLM_Locally.md","sourceDirName":"commands","slug":"/commands/LLM Locally","permalink":"/docs/commands/LLM Locally","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"id":"LLM Locally","title":"LLM Locally","sidebar_label":"LLM Locally"},"sidebar":"tutorialSidebar","previous":{"title":"Jupyter Notebook","permalink":"/docs/commands/Jupyter_Notebook"},"next":{"title":"Lightning Fast","permalink":"/docs/commands/Lightning Fast"}}');var o=a(4848),s=a(8453);const r={id:"LLM Locally",title:"LLM Locally",sidebar_label:"LLM Locally"},t=void 0,i={},d=[{value:"Change Ollama Models Directory in Ubuntu Linux",id:"change-ollama-models-directory-in-ubuntu-linux",level:2},{value:"1.1. Copy installed ollama models from one disk to another",id:"11-copy-installed-ollama-models-from-one-disk-to-another",level:3},{value:"1.2. Get it from any other system (Linux) in your network",id:"12-get-it-from-any-other-system-linux-in-your-network",level:3},{value:"2. Stop Ollama Service (optional but recommended)",id:"2-stop-ollama-service-optional-but-recommended",level:3},{value:"3. Get user and group owner names of your destination folder",id:"3-get-user-and-group-owner-names-of-your-destination-folder",level:3},{value:"4. Create and Override Ollama service using config file",id:"4-create-and-override-ollama-service-using-config-file",level:3},{value:"5. Restart System Daemon (this is not a system reboot) and Ollama",id:"5-restart-system-daemon-this-is-not-a-system-reboot-and-ollama",level:3},{value:"6. Check the working",id:"6-check-the-working",level:3},{value:"7. Try downloading a model and check if it is saving to the new location",id:"7-try-downloading-a-model-and-check-if-it-is-saving-to-the-new-location",level:3},{value:"Optionals",id:"optionals",level:2},{value:"Check details of all directories",id:"check-details-of-all-directories",level:3},{value:"Status of Ollama",id:"status-of-ollama",level:3},{value:"Error logs of Ollama",id:"error-logs-of-ollama",level:3},{value:"Ollama and Open WebUI from separate computers",id:"ollama-and-open-webui-from-separate-computers",level:2}];function c(e){const l={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",hr:"hr",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(l.p,{children:"To put an LLM locally (which works similar to ChatGPT) we need two components - Ollama and Open WebUI. In this process we need to use both Ollama and Open WebUI, that is why I made a separate file for detailing the process of making LLM work locally."}),"\n",(0,o.jsxs)(l.blockquote,{children:["\n",(0,o.jsx)(l.p,{children:"Ollama manages the downloading, loading/unloading, deleting, making new models and more of LLMs gracefully."}),"\n"]}),"\n",(0,o.jsxs)(l.blockquote,{children:["\n",(0,o.jsx)(l.p,{children:"Open WebUI is the user interface similar to ChatGPT but with much more features hidden inside."}),"\n"]}),"\n",(0,o.jsx)(l.hr,{}),"\n",(0,o.jsx)(l.h2,{id:"change-ollama-models-directory-in-ubuntu-linux",children:"Change Ollama Models Directory in Ubuntu Linux"}),"\n",(0,o.jsx)(l.h3,{id:"11-copy-installed-ollama-models-from-one-disk-to-another",children:"1.1. Copy installed ollama models from one disk to another"}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-bash",children:"cp -r <curret/path/to/models> <destination/to/store/model/files>\n"})}),"\n",(0,o.jsxs)(l.ul,{children:["\n",(0,o.jsxs)(l.li,{children:["Example command: ",(0,o.jsx)(l.code,{children:"cp -r /mnt/INTERNAL/Ollama/.ollama /home/appuser/Ollama/.ollama"})]}),"\n"]}),"\n",(0,o.jsx)("br",{}),"\n",(0,o.jsx)(l.h3,{id:"12-get-it-from-any-other-system-linux-in-your-network",children:"1.2. Get it from any other system (Linux) in your network"}),"\n",(0,o.jsx)(l.p,{children:(0,o.jsx)(l.a,{href:"/docs/commands/Secure%20Copy",children:"See Secure Copy (SCP)"})}),"\n",(0,o.jsx)("br",{}),"\n",(0,o.jsx)(l.h3,{id:"2-stop-ollama-service-optional-but-recommended",children:"2. Stop Ollama Service (optional but recommended)"}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-bash",children:"sudo systemctl stop ollama\n"})}),"\n",(0,o.jsx)("br",{}),"\n",(0,o.jsx)(l.h3,{id:"3-get-user-and-group-owner-names-of-your-destination-folder",children:"3. Get user and group owner names of your destination folder"}),"\n",(0,o.jsx)(l.p,{children:"Go to the folder where you're going to keep ollama files"}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-bash",children:"cd /home/appuser/Ollama/.ollama (Example)\n"})}),"\n",(0,o.jsx)(l.p,{children:"Check details of all files"}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-bash",children:"ls -lk -a\n"})}),"\n",(0,o.jsx)("br",{}),"\n",(0,o.jsx)(l.h3,{id:"4-create-and-override-ollama-service-using-config-file",children:"4. Create and Override Ollama service using config file"}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-bash",children:"sudo mkdir -p /etc/systemd/system/ollama.service.d; sudo nano /etc/systemd/system/ollama.service.d/override.conf\n"})}),"\n",(0,o.jsxs)(l.p,{children:["Add the ",(0,o.jsx)(l.code,{children:"path"}),", ",(0,o.jsx)(l.code,{children:"user"}),", and ",(0,o.jsx)(l.code,{children:"group"})," of new location in the file"]}),"\n",(0,o.jsx)(l.p,{children:"Example"}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-bash",children:'[Service]\nEnvironment="OLLAMA_MODELS=/home/appuser/ollama/.ollama/models" # change this path to your path\nUser=appuser # change this path to your User\nGroup=appuser # change this path to your Group\n'})}),"\n",(0,o.jsx)("br",{}),"\n",(0,o.jsx)(l.h3,{id:"5-restart-system-daemon-this-is-not-a-system-reboot-and-ollama",children:"5. Restart System Daemon (this is not a system reboot) and Ollama"}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-bash",children:"sudo systemctl daemon-reload\n\nsudo systemctl restart ollama\n"})}),"\n",(0,o.jsx)("br",{}),"\n",(0,o.jsx)(l.h3,{id:"6-check-the-working",children:"6. Check the working"}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-bash",children:"ollama list\n"})}),"\n",(0,o.jsx)("br",{}),"\n",(0,o.jsx)(l.h3,{id:"7-try-downloading-a-model-and-check-if-it-is-saving-to-the-new-location",children:"7. Try downloading a model and check if it is saving to the new location"}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-bash",children:"ollama run <model_name>\n"})}),"\n",(0,o.jsxs)(l.ul,{children:["\n",(0,o.jsxs)(l.li,{children:["Get new model name from ",(0,o.jsx)(l.code,{children:"ollama.com/models"})]}),"\n"]}),"\n",(0,o.jsx)("br",{}),"\n",(0,o.jsx)(l.hr,{}),"\n",(0,o.jsx)(l.h2,{id:"optionals",children:"Optionals"}),"\n",(0,o.jsx)(l.h3,{id:"check-details-of-all-directories",children:"Check details of all directories"}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-bash",children:"ls -ld -a\n"})}),"\n",(0,o.jsx)(l.h3,{id:"status-of-ollama",children:"Status of Ollama"}),"\n",(0,o.jsx)(l.p,{children:"To see status of ollama (whether it is running, stopped, exited, error)"}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-bash",children:"sudo systemctl status ollama\n"})}),"\n",(0,o.jsx)(l.h3,{id:"error-logs-of-ollama",children:"Error logs of Ollama"}),"\n",(0,o.jsx)(l.p,{children:"To see the error logs of ollama (limiting to the latest 50 lines)"}),"\n",(0,o.jsx)(l.pre,{children:(0,o.jsx)(l.code,{className:"language-bash",children:"journalctl -u ollama -n 50\n"})}),"\n",(0,o.jsx)(l.h2,{id:"ollama-and-open-webui-from-separate-computers",children:"Ollama and Open WebUI from separate computers"}),"\n",(0,o.jsx)(l.p,{children:"hidden"})]})}function m(e={}){const{wrapper:l}={...(0,s.R)(),...e.components};return l?(0,o.jsx)(l,{...e,children:(0,o.jsx)(c,{...e})}):c(e)}},8453:(e,l,a)=>{a.d(l,{R:()=>r,x:()=>t});var n=a(6540);const o={},s=n.createContext(o);function r(e){const l=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(l):{...l,...e}}),[l,e])}function t(e){let l;return l=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:r(e.components),n.createElement(s.Provider,{value:l},e.children)}}}]);